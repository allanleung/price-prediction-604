{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Problem Statement\n",
    "\n",
    "Predict the sold price / square foot of the property that sold on 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Take a Quick Look at Data Structure\n",
    "\n",
    "The goal of this section is to analyze the data and only keep data that is likely to be useful to us. Processing data for ML algorithm will be done in later sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the housing data as before. See PricingEstimateV1 for my reasons on including or excluding certain features.\n",
    "\n",
    "We are only interested in listings that sold in 2020. We will also add additional features such as Interest Rate, and assessement value of the properties from 2020 and 2019. We will also add price per square foot of nearest 5 properties of every listing. See the get_data variable in PreprocessingPipelineV3 for details on the data we will use for our purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7cabdd31a246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mPreprocessingPipelineV3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/myProject/PriceEstimation-main/PreprocessingPipelineV3.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNominatim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"myGeocoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geopy'"
     ]
    }
   ],
   "source": [
    "import PreprocessingPipelineV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data_dir = r\"C:\\Users\\KI PC\\OneDrive\\Documents\\Software Engineering and Computer Science\\Internships\\Riipen - KnockNow\\BC-House-Pricing-Model\"\n",
    "seasons_data_path = r\"C:\\Users\\KI PC\\OneDrive\\Documents\\Software Engineering and Computer Science\\Internships\\Riipen - KnockNow\\BC-House-Pricing-Model\\month_seasons.csv\"\n",
    "#mortgage rate from here: https://www.ratehub.ca/historical-mortgage-rates-widget\n",
    "interest_rate_2020_path = r\"C:\\Users\\KI PC\\OneDrive\\Documents\\Software Engineering and Computer Science\\Internships\\Riipen - KnockNow\\BC-House-Pricing-Model\\2020_month_by_month_interest_rate.csv\"\n",
    "assesement_data_path = r\"C:\\Users\\KI PC\\OneDrive\\Documents\\Software Engineering and Computer Science\\Internships\\Riipen - KnockNow\\BC-House-Pricing-Model\\West-van-assessments.csv\"\n",
    "longitude_latitude_data_path = r\"C:\\Users\\KI PC\\OneDrive\\Documents\\Software Engineering and Computer Science\\Internships\\Riipen - KnockNow\\BC-House-Pricing-Model\\longitude_latitude_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "import pandas as pd\n",
    "house_data = PreprocessingPipelineV3.load_data(house_data_dir, \"Spreadsheet\")\n",
    "assesement_data = pd.read_csv(assesement_data_path)\n",
    "seasons_data = pd.read_csv(seasons_data_path)\n",
    "interest_rate_2020_data = pd.read_csv(interest_rate_2020_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data_sold = PreprocessingPipelineV3.get_data.fit_transform([house_data, assesement_data, seasons_data, interest_rate_2020_data])\n",
    "house_data_sold.to_csv('data_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data_sold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the following columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data_sold.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen them in PricingEstimateV1. Sold Price is not actually Sold Price / Floor Area The new columns are described below\n",
    "\n",
    "- 2019/2020 Total Value, 2019/2020 Land Value, 2019/2020 Buildings Value: These are the assessed value of the properties from https://www.bcassessment.ca/\n",
    "\n",
    "- Season: Fall / Summer / Winter / Spring\n",
    "\n",
    "- Interest Rate: 5 year Mortgage Rate in the month that the property sold (https://www.ratehub.ca/historical-mortgage-rates-widget)\n",
    "\n",
    "- price_sq_ft: These are the price/sq_ft of the closest 5 properties\n",
    "\n",
    "- date_diff_tot: Total number of days difference between the sold date of subject property and the sold date of 5 nearest properties\n",
    "\n",
    "- distance_total: total distance between the five properties to the subject property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Train and Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will again use stratified sampling\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train, strat_train_labels, strat_test, strat_test_labels =  PreprocessingPipelineV3.create_train_test_set(df = house_data_sold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'strat_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1222e15a5601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrat_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrat_train_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrat_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrat_test_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'strat_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(strat_train.shape)\n",
    "print(strat_train_labels.shape)\n",
    "print(strat_test.shape)\n",
    "print(strat_test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before, we calculate the error on test set, we might have a problem where some of the labels in categorical columns such as \"S/A\", \"TypeDwel\", \"Showing Appts\" don't have the same number of categories in training and test set. Let's see if that is the case here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in PreprocessingPipelineV3.nominal_columns:\n",
    "    print('Result for :' + column)\n",
    "    print(\" \")\n",
    "    print('Categories of ' + column + ' that is present in train set but not in test set')\n",
    "    print(set(strat_train[column].unique()) - set(strat_test[column].unique()))\n",
    "    print('Categories of ' + column + ' that is present in test set but not in train set')\n",
    "    print(set(strat_test[column].unique()) - set(strat_train[column].unique()))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the test set don't have any rows where S/A is 'VWVRR' and where Showing Appts is 'Phone Seller First'. This will create a problem as we will have different number of features in training set vs. test set. To deal with this, we simply need to add enough rows (maximum of 2) from training set to train set so we don't have this problem. This is not an ideal situation as some of the rows will be used for both training and testing but the number of such rows at most will be 2. So we should be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_containing_vwval = (strat_train['S/A'] == 'VWVRR')\n",
    "rows_containing_phone_seller_first = strat_train['Showing Appts'] == 'Phone Seller First'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rows_containing_vwval & rows_containing_phone_seller_first).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are no rows that contains the missing categories in both columns. We need to add two rows to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add predictor features and labels to test dataset\n",
    "strat_test = strat_test.append(strat_train[rows_containing_vwval].head(1))\n",
    "strat_test = strat_test.append(strat_train[rows_containing_phone_seller_first].head(1))  \n",
    "strat_test_labels = strat_test_labels.append(strat_train_labels.loc[strat_test.index[-2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_labels.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(strat_train.shape)\n",
    "print(strat_train_labels.shape)\n",
    "print(strat_test.shape)\n",
    "print(strat_test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Prepare the Data for Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the pipeline data_processing_pipeline in PreprocessingPipelineV3 for details on how the data was transformed for machine learning algorithms. Most of them stayed the same from PreprocessingPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Selecting, Fine Tuning and Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of now, we have two data sets: Training Set and Test Set. Typically training set is further divided into a training set and a validation set. The reduced training set is used to train the model, and the validation set is used to fine-tune the model. For our purpose, we will use repeated cross-validation instead. In repeated cross-validation, we use many small validation sets. Each model is evaluated once per validation set after it is trained on the rest of the data. By averaging out all the evaluations of a model, we get a much accurate measure of its performance. The drawback is that the training time is multiplied by the number of validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following models for testing: Decision Tree Regressor, Random Forest Regressor, and SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Initial Model(s) Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "strat_train_prepared = PreprocessingPipelineV3.data_preprocessing_pipeline.fit_transform(strat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns are as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = (PreprocessingPipelineV3.numerical_columns +\n",
    "              PreprocessingPipelineV3.nearest_property_data_columns +\n",
    "              PreprocessingPipelineV3.ordinal_columns + \n",
    "              PreprocessingPipelineV3.one_hot_encoding_cols_catgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to show cross validation scores\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(strat_train_prepared, strat_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores_tree = cross_val_score(tree_reg, strat_train_prepared, strat_train_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores_tree)\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest_reg.fit(strat_train_prepared, strat_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_forest = cross_val_score(forest_reg, strat_train_prepared, strat_train_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-scores_forest)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are still not great but The Random Forest Regressor is outperforming the Decision Tree Regressor by a signifciant margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svm_reg = SVR(kernel=\"linear\")\n",
    "svm_reg.fit(strat_train_prepared, strat_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_svr = cross_val_score(svm_reg, strat_train_prepared, strat_train_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "svm_reg_rmse_scores = np.sqrt(-scores_svr)\n",
    "display_scores(svm_reg_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest Regressor is outperfomring by quite a margin but we may get better results with SVR when we use Grid Search or Randomized Search. So for next stage, we will only keep SVR and Random Forest Regressor\n",
    "\n",
    "In addition, Random Forest Algorithm combines the results of many decision trees to come up with results. Thus, it is unlikely to be helpful with ensemble learning. In addition, as shown above, it is likely to give better results than Decision Trees. So we will not consider Decision Tree any further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Final Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Grid Search with Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_forest = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search_forest = GridSearchCV(forest_reg, param_grid_forest, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search_forest.fit(strat_train_prepared, strat_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search_forest.best_params_)\n",
    "print(grid_search_forest.best_estimator_)\n",
    "print(\"Best Score: {0}\".format(np.sqrt(-grid_search_forest.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search_forest.cv_results_).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better way to see the result is as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search_forest.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Randomized Search with Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs_forest = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search_forest = RandomizedSearchCV(forest_reg, param_distributions=param_distribs_forest,\n",
    "                                n_iter=50, cv=5, scoring='neg_mean_squared_error', random_state=42, verbose = 2)\n",
    "rnd_search_forest.fit(strat_train_prepared, strat_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rnd_search_forest.best_params_)\n",
    "print(rnd_search_forest.best_estimator_)\n",
    "print(\"Best Score: {0}\".format(np.sqrt(-rnd_search_forest.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = rnd_search_forest.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = rnd_search_forest.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(feature_importances, attributes), reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Grid Search with SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svr = [\n",
    "        {'kernel': ['linear'], 'C': [10., 30., 100., 300., 1000., 3000., 10000., 30000.0]},\n",
    "        {'kernel': ['rbf'], 'C': [1.0, 3.0, 10., 30., 100., 300., 1000.0],\n",
    "         'gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]},\n",
    "    ]\n",
    "svm_reg = SVR()\n",
    "grid_search_svr = GridSearchCV(svm_reg, param_grid_svr, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           verbose = 2) \n",
    "\n",
    "grid_search_svr.fit(strat_train_prepared, strat_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search_svr.best_params_)\n",
    "print(grid_search_svr.best_estimator_)\n",
    "print(\"Best Score: {0}\".format(np.sqrt(-grid_search_svr.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search_svr.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Randomized Search with SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import expon, reciprocal\n",
    "param_distribs_svr = {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C': reciprocal(20, 200000),\n",
    "        'gamma': expon(scale=1.0),\n",
    "    } \n",
    "\n",
    "svm_reg = SVR()\n",
    "rnd_search_svr = RandomizedSearchCV(svm_reg, param_distributions=param_distribs_svr,\n",
    "                                n_iter=50, cv=5, scoring='neg_mean_squared_error',\n",
    "                                verbose=2, random_state=42)\n",
    "rnd_search_svr.fit(strat_train_prepared, strat_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rnd_search_svr.best_params_)\n",
    "print(rnd_search_svr.best_estimator_)\n",
    "print(\"Best Score: {0}\".format(np.sqrt(-rnd_search_svr.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cvres = rnd_search_svr.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is the SVR model obtaind from Grid Search with mean error of 131.05 $/sq_Ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Generalization Error For Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before, we calculate the error on test set, we might have a problem where some of the labels in categorical columns such as \"S/A\", \"TypeDwel\", \"Showing Appts\" don't have the same number of categories in training and test set. Let's see if that is the case here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "#final_model = grid_search_svr.best_estimator_\n",
    "final_model = grid_search_svr.best_estimator_\n",
    "house_data_test_prepared = PreprocessingPipelineV3.data_preprocessing_pipeline.fit_transform(strat_test)\n",
    "final_predictions = final_model.predict(house_data_test_prepared)\n",
    "final_mse = mean_squared_error(strat_test_labels, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(\"Final RMSE: {}\".format(final_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean error on test set is $1750.58 per square foot. The result is not great and we need better features and more data for the model to learn from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export final model\n",
    "import joblib\n",
    "joblib.dump(final_model, \"final_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
